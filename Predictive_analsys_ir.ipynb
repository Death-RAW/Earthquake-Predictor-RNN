{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:57:02.949104Z",
     "start_time": "2024-05-03T15:57:02.042632Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, hour, minute, second, col, when\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, OneHotEncoderEstimator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import PolynomialExpansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:57:13.596201Z",
     "start_time": "2024-05-03T15:57:02.951610Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    ".master(\"spark://10.129.5.252:7077\") \\\n",
    ".appName(\"USGS-ML\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:57:31.008993Z",
     "start_time": "2024-05-03T15:57:13.603624Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.option(\"delimiter\", \";\").csv(\"RAW1.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:57:32.581422Z",
     "start_time": "2024-05-03T15:57:31.013156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- depth: double (nullable = true)\n",
      " |-- mag: double (nullable = true)\n",
      " |-- magType: string (nullable = true)\n",
      " |-- nst: string (nullable = true)\n",
      " |-- gap: string (nullable = true)\n",
      " |-- dmin: string (nullable = true)\n",
      " |-- rms: string (nullable = true)\n",
      " |-- net: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- updated: string (nullable = true)\n",
      " |-- place: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- horizontalError: string (nullable = true)\n",
      " |-- depthError: string (nullable = true)\n",
      " |-- magError: string (nullable = true)\n",
      " |-- magNst: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- locationSource: string (nullable = true)\n",
      " |-- magSource: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- minute: integer (nullable = true)\n",
      " |-- second: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"year\", year(\"time\")) \\\n",
    "    .withColumn(\"month\", month(\"time\")) \\\n",
    "    .withColumn(\"day\", dayofmonth(\"time\")) \\\n",
    "    .withColumn(\"hour\", hour(\"time\")) \\\n",
    "    .withColumn(\"minute\", minute(\"time\")) \\\n",
    "    .withColumn(\"second\", second(\"time\")) \\\n",
    "    .withColumn(\"depth\", col(\"depth\").cast(\"double\")) \\\n",
    "    .withColumn(\"mag\", col(\"mag\").cast(\"double\")) \\\n",
    "    .withColumn(\"latitude\", col(\"latitude\").cast(\"double\")) \\\n",
    "    .withColumn(\"longitude\", col(\"longitude\").cast(\"double\"))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:57:32.678857Z",
     "start_time": "2024-05-03T15:57:32.587231Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.filter((col(\"depth\").isNotNull()) & (col(\"mag\").isNotNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:57:32.776085Z",
     "start_time": "2024-05-03T15:57:32.681270Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:58:51.045050Z",
     "start_time": "2024-05-03T15:57:32.778294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) after optimization: 0.4015175335524103\n"
     ]
    }
   ],
   "source": [
    "# Select features and target variable\n",
    "feature_cols = ['latitude', 'longitude', 'depth']  \n",
    "target_col = 'mag'\n",
    "\n",
    "# Assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='xx')\n",
    "data = assembler.transform(train_data).select('xx', target_col)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=10)\n",
    "\n",
    "poly_expansion = PolynomialExpansion(inputCol='xx', outputCol='xx_poly', degree=2)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler(inputCol='xx_poly', outputCol='features', withStd=True, withMean=True)\n",
    "\n",
    "# Linear Regression model\n",
    "lr = LinearRegression(featuresCol='features', labelCol=target_col)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[poly_expansion, scaler, lr])\n",
    "\n",
    "# Hyperparameter grid for regularization strength (alpha)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01, 0.001]) \\\n",
    "    .build()\n",
    "\n",
    "# Cross-validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=RegressionEvaluator(labelCol=target_col, predictionCol='prediction', metricName='rmse'),\n",
    "                          numFolds=2)\n",
    "\n",
    "# Train the model\n",
    "cv_model = crossval.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=target_col, predictionCol='prediction', metricName='rmse')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) after optimization:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:00:10.906069Z",
     "start_time": "2024-05-03T15:58:51.049503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearRegression...\n",
      "LinearRegression RMSE: 0.3956456412135186\n",
      "Training GeneralizedLinearRegression...\n",
      "GeneralizedLinearRegression RMSE: 0.3956456412135186\n",
      "Training IsotonicRegression...\n",
      "IsotonicRegression RMSE: 0.39906875309894774\n",
      "Training DecisionTreeRegressor...\n",
      "DecisionTreeRegressor RMSE: 0.3903016692979934\n",
      "Training RandomForestRegressor...\n",
      "RandomForestRegressor RMSE: 0.39041635465500457\n",
      "Training GBTRegressor...\n",
      "GBTRegressor RMSE: 0.385958922169134\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression, IsotonicRegression, LinearRegression\n",
    "from pyspark.ml.regression import DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# features and target column\n",
    "feature_cols = ['latitude', 'longitude', 'depth', 'year', 'month']\n",
    "target_col = 'mag'\n",
    "\n",
    "# Assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='xx')\n",
    "data = assembler.transform(df).select('xx', target_col)\n",
    "\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=10)\n",
    "\n",
    "#regression models\n",
    "models = [\n",
    "    LinearRegression(featuresCol='xx', labelCol=target_col),\n",
    "    GeneralizedLinearRegression(featuresCol='xx', labelCol=target_col),\n",
    "    IsotonicRegression(featuresCol='xx', labelCol=target_col),\n",
    "    DecisionTreeRegressor(featuresCol='xx', labelCol=target_col),\n",
    "    RandomForestRegressor(featuresCol='xx', labelCol=target_col),\n",
    "    GBTRegressor(featuresCol='xx', labelCol=target_col)\n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model in models:\n",
    "    # Train the model\n",
    "    model_name = model.__class__.__name__\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model = model.fit(train_data)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    predictions = model.transform(test_data)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluator = RegressionEvaluator(labelCol=target_col, predictionCol='prediction', metricName='rmse')\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    \n",
    "    # Print the RMSE\n",
    "    print(f\"{model_name} RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:00:10.915486Z",
     "start_time": "2024-05-03T16:00:10.910430Z"
    }
   },
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(featuresCol='xx', labelCol=target_col)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(gbt.maxIter, [10, 20, 30]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=target_col, predictionCol='prediction', metricName='rmse')\n",
    "\n",
    "# Create CrossValidator\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cv_model = crossval.fit(train_data)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) after cross-validation:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:00:17.023486Z",
     "start_time": "2024-05-03T16:00:10.919172Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=target_col, predictionCol='prediction', metricName='rmse')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) after optimization:\", rmse)\n",
    "\n",
    "# Now, let's use the test data split from the original dataset to make predictions and evaluate each trained model\n",
    "\n",
    "# Make predictions using each trained model on the original test data split\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    print(f\"\\n{model_name} Predictions:\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.transform(test_data)\n",
    "    \n",
    "    # Evaluate the predictions\n",
    "    evaluator = RegressionEvaluator(labelCol=target_col, predictionCol='prediction', metricName='rmse')\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    \n",
    "    # Print RMSE\n",
    "    print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
